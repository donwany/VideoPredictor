{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 284\n",
      "[INFO] loading images...\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: extra compressed data\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: extra compressed data\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "2021-11-06 17:15:55.049581: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[INFO] compiling model...\n",
      "[INFO] training head...\n",
      "2021-11-06 17:16:02.440971: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "Epoch 1/50\n",
      "110/110 [==============================] - 906s 8s/step - loss: 2.2969 - accuracy: 0.2559 - val_loss: 1.2748 - val_accuracy: 0.5486\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 1103s 10s/step - loss: 1.5136 - accuracy: 0.4562 - val_loss: 0.9418 - val_accuracy: 0.6892\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 923s 8s/step - loss: 1.2376 - accuracy: 0.5510 - val_loss: 0.8013 - val_accuracy: 0.7543\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 873s 8s/step - loss: 1.1188 - accuracy: 0.6043 - val_loss: 0.7266 - val_accuracy: 0.7717\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 891s 8s/step - loss: 1.0009 - accuracy: 0.6355 - val_loss: 0.6785 - val_accuracy: 0.7752\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 876s 8s/step - loss: 0.9306 - accuracy: 0.6616 - val_loss: 0.6315 - val_accuracy: 0.7917\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 855s 8s/step - loss: 0.8676 - accuracy: 0.6888 - val_loss: 0.5948 - val_accuracy: 0.8082\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 942s 9s/step - loss: 0.8325 - accuracy: 0.7032 - val_loss: 0.5603 - val_accuracy: 0.8142\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 942s 9s/step - loss: 0.8077 - accuracy: 0.7095 - val_loss: 0.5441 - val_accuracy: 0.8203\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - 858s 8s/step - loss: 0.7605 - accuracy: 0.7298 - val_loss: 0.5212 - val_accuracy: 0.8194\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - 869s 8s/step - loss: 0.7291 - accuracy: 0.7387 - val_loss: 0.5094 - val_accuracy: 0.8255\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - 874s 8s/step - loss: 0.6938 - accuracy: 0.7593 - val_loss: 0.4964 - val_accuracy: 0.8299\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - 878s 8s/step - loss: 0.6912 - accuracy: 0.7573 - val_loss: 0.4852 - val_accuracy: 0.8351\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - 926s 8s/step - loss: 0.6659 - accuracy: 0.7711 - val_loss: 0.4792 - val_accuracy: 0.8368\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - 920s 8s/step - loss: 0.6519 - accuracy: 0.7782 - val_loss: 0.4617 - val_accuracy: 0.8420\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - 946s 9s/step - loss: 0.6400 - accuracy: 0.7819 - val_loss: 0.4487 - val_accuracy: 0.8559\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - 904s 8s/step - loss: 0.6090 - accuracy: 0.7885 - val_loss: 0.4491 - val_accuracy: 0.8498\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - 890s 8s/step - loss: 0.6211 - accuracy: 0.7834 - val_loss: 0.4322 - val_accuracy: 0.8542\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - 889s 8s/step - loss: 0.6023 - accuracy: 0.7871 - val_loss: 0.4366 - val_accuracy: 0.8550\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - 987s 9s/step - loss: 0.5834 - accuracy: 0.7923 - val_loss: 0.4270 - val_accuracy: 0.8576\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - 935s 9s/step - loss: 0.5723 - accuracy: 0.8026 - val_loss: 0.4131 - val_accuracy: 0.8602\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - 927s 8s/step - loss: 0.5596 - accuracy: 0.8037 - val_loss: 0.4209 - val_accuracy: 0.8542\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - 894s 8s/step - loss: 0.5497 - accuracy: 0.8123 - val_loss: 0.4112 - val_accuracy: 0.8663\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - 1329s 12s/step - loss: 0.5265 - accuracy: 0.8149 - val_loss: 0.3956 - val_accuracy: 0.8724\n",
      "Epoch 25/50\n",
      "110/110 [==============================] - 1225s 11s/step - loss: 0.5297 - accuracy: 0.8158 - val_loss: 0.3955 - val_accuracy: 0.8672\n",
      "Epoch 26/50\n",
      "110/110 [==============================] - 1124s 10s/step - loss: 0.5192 - accuracy: 0.8212 - val_loss: 0.4073 - val_accuracy: 0.8594\n",
      "Epoch 27/50\n",
      "110/110 [==============================] - 1305s 12s/step - loss: 0.5144 - accuracy: 0.8229 - val_loss: 0.3903 - val_accuracy: 0.8724\n",
      "Epoch 28/50\n",
      "110/110 [==============================] - 1243s 11s/step - loss: 0.4958 - accuracy: 0.8215 - val_loss: 0.3828 - val_accuracy: 0.8733\n",
      "Epoch 29/50\n",
      "110/110 [==============================] - 1369s 12s/step - loss: 0.5015 - accuracy: 0.8312 - val_loss: 0.3829 - val_accuracy: 0.8741\n",
      "Epoch 30/50\n",
      "110/110 [==============================] - 1390s 13s/step - loss: 0.5094 - accuracy: 0.8232 - val_loss: 0.3768 - val_accuracy: 0.8785\n",
      "Epoch 31/50\n",
      "110/110 [==============================] - 1343s 12s/step - loss: 0.4693 - accuracy: 0.8384 - val_loss: 0.3764 - val_accuracy: 0.8785\n",
      "Epoch 32/50\n",
      "110/110 [==============================] - 1314s 12s/step - loss: 0.4739 - accuracy: 0.8370 - val_loss: 0.3812 - val_accuracy: 0.8793\n",
      "Epoch 33/50\n",
      "110/110 [==============================] - 1226s 11s/step - loss: 0.4801 - accuracy: 0.8367 - val_loss: 0.3752 - val_accuracy: 0.8811\n",
      "Epoch 34/50\n",
      "110/110 [==============================] - 1056s 10s/step - loss: 0.4702 - accuracy: 0.8378 - val_loss: 0.3693 - val_accuracy: 0.8819\n",
      "Epoch 35/50\n",
      "110/110 [==============================] - 1277s 12s/step - loss: 0.4524 - accuracy: 0.8447 - val_loss: 0.3669 - val_accuracy: 0.8793\n",
      "Epoch 36/50\n",
      "110/110 [==============================] - 1142s 10s/step - loss: 0.4621 - accuracy: 0.8418 - val_loss: 0.3688 - val_accuracy: 0.8793\n",
      "Epoch 37/50\n",
      "110/110 [==============================] - 1025s 9s/step - loss: 0.4663 - accuracy: 0.8370 - val_loss: 0.3622 - val_accuracy: 0.8802\n",
      "Epoch 38/50\n",
      "110/110 [==============================] - 1010s 9s/step - loss: 0.4520 - accuracy: 0.8467 - val_loss: 0.3557 - val_accuracy: 0.8854\n",
      "Epoch 39/50\n",
      "110/110 [==============================] - 990s 9s/step - loss: 0.4603 - accuracy: 0.8341 - val_loss: 0.3668 - val_accuracy: 0.8802\n",
      "Epoch 40/50\n",
      "110/110 [==============================] - 1032s 9s/step - loss: 0.4449 - accuracy: 0.8516 - val_loss: 0.3639 - val_accuracy: 0.8819\n",
      "Epoch 41/50\n",
      "110/110 [==============================] - 977s 9s/step - loss: 0.4334 - accuracy: 0.8588 - val_loss: 0.3541 - val_accuracy: 0.8854\n",
      "Epoch 42/50\n",
      "110/110 [==============================] - 940s 9s/step - loss: 0.4330 - accuracy: 0.8539 - val_loss: 0.3558 - val_accuracy: 0.8837\n",
      "Epoch 43/50\n",
      "110/110 [==============================] - 892s 8s/step - loss: 0.4247 - accuracy: 0.8530 - val_loss: 0.3550 - val_accuracy: 0.8819\n",
      "Epoch 44/50\n",
      "110/110 [==============================] - 891s 8s/step - loss: 0.4149 - accuracy: 0.8567 - val_loss: 0.3452 - val_accuracy: 0.8880\n",
      "Epoch 45/50\n",
      "110/110 [==============================] - 891s 8s/step - loss: 0.4139 - accuracy: 0.8564 - val_loss: 0.3537 - val_accuracy: 0.8828\n",
      "Epoch 46/50\n",
      "110/110 [==============================] - 862s 8s/step - loss: 0.4036 - accuracy: 0.8633 - val_loss: 0.3466 - val_accuracy: 0.8889\n",
      "Epoch 47/50\n",
      "110/110 [==============================] - 881s 8s/step - loss: 0.4072 - accuracy: 0.8619 - val_loss: 0.3449 - val_accuracy: 0.8845\n",
      "Epoch 48/50\n",
      "110/110 [==============================] - 852s 8s/step - loss: 0.3987 - accuracy: 0.8639 - val_loss: 0.3437 - val_accuracy: 0.8880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "110/110 [==============================] - 855s 8s/step - loss: 0.4148 - accuracy: 0.8616 - val_loss: 0.3470 - val_accuracy: 0.8854\n",
      "Epoch 50/50\n",
      "110/110 [==============================] - 874s 8s/step - loss: 0.3946 - accuracy: 0.8593 - val_loss: 0.3575 - val_accuracy: 0.8854\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    baseball       0.95      0.86      0.90       183\n",
      "  basketball       0.86      0.85      0.86       122\n",
      "      boxing       0.93      0.93      0.93       176\n",
      "    football       0.82      0.94      0.88       196\n",
      "  gymnastics       0.94      0.92      0.93       178\n",
      "      hockey       0.84      0.70      0.77       142\n",
      "  ice_hockey       0.87      0.94      0.90       177\n",
      "\n",
      "    accuracy                           0.89      1174\n",
      "   macro avg       0.89      0.88      0.88      1174\n",
      "weighted avg       0.89      0.89      0.88      1174\n",
      "\n",
      "[INFO] serializing network...\n",
      "/Users/tsiameh/Library/Python/3.8/lib/python/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "!python3.8 train.py \\\n",
    "   --dataset Sports-Type-Classifier/data \\\n",
    "   --model model/activity.model \\\n",
    "   --label-bin model/lb.pickle \\\n",
    "   --epochs 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: extra compressed data\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: extra compressed data\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "2021-11-07 10:21:09.541151: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[INFO] compiling model...\n",
      "[INFO] training head...\n",
      "2021-11-07 10:21:11.856090: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "Epoch 1/50\n",
      "110/110 [==============================] - 685s 6s/step - loss: 5.6648 - accuracy: 0.2968 - val_loss: 1.7590 - val_accuracy: 0.5859\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 833s 8s/step - loss: 2.6402 - accuracy: 0.4713 - val_loss: 1.2421 - val_accuracy: 0.6710\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 826s 8s/step - loss: 1.8205 - accuracy: 0.5519 - val_loss: 1.0548 - val_accuracy: 0.7031\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 772s 7s/step - loss: 1.5416 - accuracy: 0.5862 - val_loss: 0.9343 - val_accuracy: 0.7352\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 852s 8s/step - loss: 1.3416 - accuracy: 0.6140 - val_loss: 0.8844 - val_accuracy: 0.7378\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 795s 7s/step - loss: 1.2045 - accuracy: 0.6372 - val_loss: 0.8092 - val_accuracy: 0.7526\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 708s 6s/step - loss: 1.1435 - accuracy: 0.6410 - val_loss: 0.7979 - val_accuracy: 0.7569\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 698s 6s/step - loss: 1.0655 - accuracy: 0.6653 - val_loss: 0.7560 - val_accuracy: 0.7708\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 728s 7s/step - loss: 1.0082 - accuracy: 0.6774 - val_loss: 0.7429 - val_accuracy: 0.7769\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - ETA: 0s - loss: 0.9672 - accuracy: 0.6903^C\n"
     ]
    }
   ],
   "source": [
    "!python3.8 train.py \\\n",
    "   --dataset Sports-Type-Classifier/data \\\n",
    "   --model model/activity.model \\\n",
    "   --label-bin model/lb.pickle \\\n",
    "   --epochs 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: extra compressed data\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: extra compressed data\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "2021-11-11 02:12:39.948751: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[INFO] compiling model...\n",
      "[INFO] training head...\n",
      "2021-11-11 02:12:47.590662: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "Epoch 1/50\n",
      "110/110 [==============================] - 712s 6s/step - loss: 3.4282 - accuracy: 0.3596 - val_loss: 1.5744 - val_accuracy: 0.4922\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 30484s 280s/step - loss: 1.5333 - accuracy: 0.4716 - val_loss: 1.3806 - val_accuracy: 0.5312\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 657s 6s/step - loss: 1.3881 - accuracy: 0.5069 - val_loss: 1.2894 - val_accuracy: 0.5547\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 850s 8s/step - loss: 1.3377 - accuracy: 0.5261 - val_loss: 1.2552 - val_accuracy: 0.5738\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 1061s 10s/step - loss: 1.2682 - accuracy: 0.5507 - val_loss: 1.2273 - val_accuracy: 0.5668\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 1038s 9s/step - loss: 1.2302 - accuracy: 0.5599 - val_loss: 1.1453 - val_accuracy: 0.6137\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 1210s 11s/step - loss: 1.2036 - accuracy: 0.5653 - val_loss: 1.1927 - val_accuracy: 0.5799\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 1175s 11s/step - loss: 1.1830 - accuracy: 0.5794 - val_loss: 1.1083 - val_accuracy: 0.6042\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 1076s 10s/step - loss: 1.1292 - accuracy: 0.5905 - val_loss: 1.1019 - val_accuracy: 0.6215\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - 982s 9s/step - loss: 1.1266 - accuracy: 0.6135 - val_loss: 1.1045 - val_accuracy: 0.6059\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - 1034s 9s/step - loss: 1.1042 - accuracy: 0.6109 - val_loss: 1.1019 - val_accuracy: 0.6241\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - 1415s 13s/step - loss: 1.0746 - accuracy: 0.6206 - val_loss: 1.1370 - val_accuracy: 0.6120\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - 820s 7s/step - loss: 1.0491 - accuracy: 0.6241 - val_loss: 1.0586 - val_accuracy: 0.6345\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - 959s 9s/step - loss: 1.0770 - accuracy: 0.6172 - val_loss: 1.0473 - val_accuracy: 0.6389\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - 948s 9s/step - loss: 1.0229 - accuracy: 0.6330 - val_loss: 1.0370 - val_accuracy: 0.6345\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - 1002s 9s/step - loss: 0.9965 - accuracy: 0.6436 - val_loss: 1.0296 - val_accuracy: 0.6432\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - 1043s 9s/step - loss: 1.0038 - accuracy: 0.6424 - val_loss: 1.0314 - val_accuracy: 0.6571\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - 1001s 9s/step - loss: 0.9843 - accuracy: 0.6501 - val_loss: 1.0080 - val_accuracy: 0.6536\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - 957s 9s/step - loss: 0.9938 - accuracy: 0.6461 - val_loss: 1.0195 - val_accuracy: 0.6545\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - 1086s 10s/step - loss: 0.9520 - accuracy: 0.6599 - val_loss: 1.0107 - val_accuracy: 0.6580\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - 1035s 9s/step - loss: 0.9573 - accuracy: 0.6616 - val_loss: 0.9780 - val_accuracy: 0.6589\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - 1116s 10s/step - loss: 0.9584 - accuracy: 0.6622 - val_loss: 1.0062 - val_accuracy: 0.6736\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - 1085s 10s/step - loss: 0.9220 - accuracy: 0.6711 - val_loss: 1.0286 - val_accuracy: 0.6536\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - 1077s 10s/step - loss: 0.9286 - accuracy: 0.6596 - val_loss: 0.9765 - val_accuracy: 0.6658\n",
      "Epoch 25/50\n",
      "110/110 [==============================] - 1083s 10s/step - loss: 0.9105 - accuracy: 0.6699 - val_loss: 0.9389 - val_accuracy: 0.6719\n",
      "Epoch 26/50\n",
      "110/110 [==============================] - 1120s 10s/step - loss: 0.8994 - accuracy: 0.6868 - val_loss: 0.9523 - val_accuracy: 0.6710\n",
      "Epoch 27/50\n",
      "110/110 [==============================] - 3092s 28s/step - loss: 0.9175 - accuracy: 0.6828 - val_loss: 0.9545 - val_accuracy: 0.6780\n",
      "Epoch 28/50\n",
      "110/110 [==============================] - 809s 7s/step - loss: 0.8967 - accuracy: 0.6811 - val_loss: 0.9817 - val_accuracy: 0.6675\n",
      "Epoch 29/50\n",
      "110/110 [==============================] - 1281s 12s/step - loss: 0.8831 - accuracy: 0.6854 - val_loss: 0.9196 - val_accuracy: 0.6936\n",
      "Epoch 30/50\n",
      "110/110 [==============================] - 916s 8s/step - loss: 0.8901 - accuracy: 0.6891 - val_loss: 0.9516 - val_accuracy: 0.6727\n",
      "Epoch 31/50\n",
      "110/110 [==============================] - 1103s 10s/step - loss: 0.8673 - accuracy: 0.6957 - val_loss: 0.9448 - val_accuracy: 0.6727\n",
      "Epoch 32/50\n",
      "110/110 [==============================] - 1133s 10s/step - loss: 0.8660 - accuracy: 0.6917 - val_loss: 0.9287 - val_accuracy: 0.6892\n",
      "Epoch 33/50\n",
      "110/110 [==============================] - 1171s 11s/step - loss: 0.8753 - accuracy: 0.6980 - val_loss: 0.9090 - val_accuracy: 0.6875\n",
      "Epoch 34/50\n",
      "110/110 [==============================] - 1103s 10s/step - loss: 0.8440 - accuracy: 0.7034 - val_loss: 0.9335 - val_accuracy: 0.6806\n",
      "Epoch 35/50\n",
      "110/110 [==============================] - 1102s 10s/step - loss: 0.8717 - accuracy: 0.6905 - val_loss: 0.9202 - val_accuracy: 0.6797\n",
      "Epoch 36/50\n",
      "110/110 [==============================] - 1133s 10s/step - loss: 0.8288 - accuracy: 0.7063 - val_loss: 0.8934 - val_accuracy: 0.6936\n",
      "Epoch 37/50\n",
      "110/110 [==============================] - 1103s 10s/step - loss: 0.8341 - accuracy: 0.7083 - val_loss: 0.9015 - val_accuracy: 0.6858\n",
      "Epoch 38/50\n",
      "110/110 [==============================] - 1184s 11s/step - loss: 0.8072 - accuracy: 0.7172 - val_loss: 0.9239 - val_accuracy: 0.6788\n",
      "Epoch 39/50\n",
      "110/110 [==============================] - 1088s 10s/step - loss: 0.8048 - accuracy: 0.7169 - val_loss: 0.8812 - val_accuracy: 0.6979\n",
      "Epoch 40/50\n",
      "110/110 [==============================] - 1035s 9s/step - loss: 0.8111 - accuracy: 0.7166 - val_loss: 0.8703 - val_accuracy: 0.6988\n",
      "Epoch 41/50\n",
      "110/110 [==============================] - 968s 9s/step - loss: 0.8144 - accuracy: 0.7097 - val_loss: 0.8929 - val_accuracy: 0.6953\n",
      "Epoch 42/50\n",
      "110/110 [==============================] - 1089s 10s/step - loss: 0.8286 - accuracy: 0.7109 - val_loss: 0.9272 - val_accuracy: 0.6806\n",
      "Epoch 43/50\n",
      "110/110 [==============================] - 1062s 10s/step - loss: 0.8317 - accuracy: 0.7043 - val_loss: 0.9001 - val_accuracy: 0.6962\n",
      "Epoch 44/50\n",
      "110/110 [==============================] - 1039s 9s/step - loss: 0.8201 - accuracy: 0.7077 - val_loss: 0.8655 - val_accuracy: 0.6953\n",
      "Epoch 45/50\n",
      "110/110 [==============================] - 917s 8s/step - loss: 0.8014 - accuracy: 0.7126 - val_loss: 0.8552 - val_accuracy: 0.6953\n",
      "Epoch 46/50\n",
      "110/110 [==============================] - 946s 9s/step - loss: 0.7880 - accuracy: 0.7143 - val_loss: 0.8516 - val_accuracy: 0.7014\n",
      "Epoch 47/50\n",
      "110/110 [==============================] - 949s 9s/step - loss: 0.8062 - accuracy: 0.7103 - val_loss: 0.9398 - val_accuracy: 0.6649\n",
      "Epoch 48/50\n",
      "110/110 [==============================] - 829s 8s/step - loss: 0.7995 - accuracy: 0.7226 - val_loss: 0.9060 - val_accuracy: 0.6962\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 784s 7s/step - loss: 0.7546 - accuracy: 0.7264 - val_loss: 0.8798 - val_accuracy: 0.6944\n",
      "Epoch 50/50\n",
      "110/110 [==============================] - 817s 7s/step - loss: 0.7816 - accuracy: 0.7221 - val_loss: 0.8749 - val_accuracy: 0.6944\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    baseball       0.79      0.55      0.65       183\n",
      "  basketball       0.52      0.75      0.61       122\n",
      "      boxing       0.70      0.80      0.75       176\n",
      "    football       0.65      0.80      0.72       196\n",
      "  gymnastics       0.73      0.48      0.58       178\n",
      "      hockey       0.71      0.58      0.64       142\n",
      "  ice_hockey       0.79      0.89      0.83       177\n",
      "\n",
      "    accuracy                           0.69      1174\n",
      "   macro avg       0.70      0.69      0.68      1174\n",
      "weighted avg       0.71      0.69      0.69      1174\n",
      "\n",
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "!python3.8 train.py \\\n",
    "   --dataset Sports-Type-Classifier/data \\\n",
    "   --model model/activity.model \\\n",
    "   --label-bin model/lb.pickle \\\n",
    "   --epochs 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: extra compressed data\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: extra compressed data\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "2021-11-10 02:35:45.104997: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[INFO] compiling model...\n",
      "[INFO] training head...\n",
      "2021-11-10 02:35:51.438523: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "Epoch 1/50\n",
      "110/110 [==============================] - 108s 945ms/step - loss: 8.6422 - accuracy: 0.2054 - val_loss: 1.9655 - val_accuracy: 0.2352\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 126s 1s/step - loss: 2.0162 - accuracy: 0.2281 - val_loss: 1.8771 - val_accuracy: 0.2682\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 145s 1s/step - loss: 1.9518 - accuracy: 0.2335 - val_loss: 1.8783 - val_accuracy: 0.2760\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 165s 1s/step - loss: 1.9165 - accuracy: 0.2372 - val_loss: 1.8617 - val_accuracy: 0.2795\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 2783s 26s/step - loss: 1.9062 - accuracy: 0.2413 - val_loss: 1.8261 - val_accuracy: 0.2917\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 130s 1s/step - loss: 1.9006 - accuracy: 0.2447 - val_loss: 1.8031 - val_accuracy: 0.3030\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 127s 1s/step - loss: 1.8632 - accuracy: 0.2702 - val_loss: 1.7853 - val_accuracy: 0.3090\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 133s 1s/step - loss: 1.8564 - accuracy: 0.2831 - val_loss: 1.7904 - val_accuracy: 0.3047\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 138s 1s/step - loss: 1.8401 - accuracy: 0.2725 - val_loss: 1.7657 - val_accuracy: 0.3203\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - 23667s 217s/step - loss: 1.8518 - accuracy: 0.2564 - val_loss: 1.7471 - val_accuracy: 0.3255\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - 104s 944ms/step - loss: 1.8296 - accuracy: 0.2768 - val_loss: 1.7465 - val_accuracy: 0.3490\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - 119s 1s/step - loss: 1.8172 - accuracy: 0.2777 - val_loss: 1.7418 - val_accuracy: 0.3290\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - 121s 1s/step - loss: 1.8188 - accuracy: 0.2811 - val_loss: 1.7362 - val_accuracy: 0.3273\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - 128s 1s/step - loss: 1.8076 - accuracy: 0.2785 - val_loss: 1.7199 - val_accuracy: 0.3411\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - 139s 1s/step - loss: 1.8136 - accuracy: 0.2791 - val_loss: 1.7189 - val_accuracy: 0.3411\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - 148s 1s/step - loss: 1.7839 - accuracy: 0.2948 - val_loss: 1.7022 - val_accuracy: 0.3438\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - 2113s 19s/step - loss: 1.7921 - accuracy: 0.2923 - val_loss: 1.6971 - val_accuracy: 0.3559\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - 137s 1s/step - loss: 1.7814 - accuracy: 0.3014 - val_loss: 1.7096 - val_accuracy: 0.3351\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - 102s 924ms/step - loss: 1.7814 - accuracy: 0.2805 - val_loss: 1.7094 - val_accuracy: 0.3316\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - 114s 1s/step - loss: 1.7639 - accuracy: 0.2977 - val_loss: 1.6886 - val_accuracy: 0.3464\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - 136s 1s/step - loss: 1.7801 - accuracy: 0.2946 - val_loss: 1.6935 - val_accuracy: 0.3516\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - 139s 1s/step - loss: 1.7861 - accuracy: 0.2966 - val_loss: 1.6850 - val_accuracy: 0.3481\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - 142s 1s/step - loss: 1.7641 - accuracy: 0.3026 - val_loss: 1.6831 - val_accuracy: 0.3516\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - 143s 1s/step - loss: 1.7735 - accuracy: 0.3049 - val_loss: 1.6831 - val_accuracy: 0.3455\n",
      "Epoch 25/50\n",
      "110/110 [==============================] - 146s 1s/step - loss: 1.7652 - accuracy: 0.3063 - val_loss: 1.6681 - val_accuracy: 0.3472\n",
      "Epoch 26/50\n",
      "110/110 [==============================] - 151s 1s/step - loss: 1.7705 - accuracy: 0.3011 - val_loss: 1.6755 - val_accuracy: 0.3481\n",
      "Epoch 27/50\n",
      "110/110 [==============================] - 153s 1s/step - loss: 1.7427 - accuracy: 0.3089 - val_loss: 1.6777 - val_accuracy: 0.3472\n",
      "Epoch 28/50\n",
      "110/110 [==============================] - 154s 1s/step - loss: 1.7591 - accuracy: 0.3086 - val_loss: 1.6690 - val_accuracy: 0.3559\n",
      "Epoch 29/50\n",
      "110/110 [==============================] - 181s 2s/step - loss: 1.7558 - accuracy: 0.3037 - val_loss: 1.6731 - val_accuracy: 0.3637\n",
      "Epoch 30/50\n",
      "110/110 [==============================] - 168s 2s/step - loss: 1.7631 - accuracy: 0.3043 - val_loss: 1.6727 - val_accuracy: 0.3550\n",
      "Epoch 31/50\n",
      "110/110 [==============================] - 157s 1s/step - loss: 1.7445 - accuracy: 0.3074 - val_loss: 1.6496 - val_accuracy: 0.3655\n",
      "Epoch 32/50\n",
      "110/110 [==============================] - 156s 1s/step - loss: 1.7538 - accuracy: 0.3089 - val_loss: 1.6664 - val_accuracy: 0.3663\n",
      "Epoch 33/50\n",
      "110/110 [==============================] - 157s 1s/step - loss: 1.7542 - accuracy: 0.3046 - val_loss: 1.6573 - val_accuracy: 0.3611\n",
      "Epoch 34/50\n",
      "110/110 [==============================] - 158s 1s/step - loss: 1.7350 - accuracy: 0.2989 - val_loss: 1.6457 - val_accuracy: 0.3585\n",
      "Epoch 35/50\n",
      "110/110 [==============================] - 205s 2s/step - loss: 1.7606 - accuracy: 0.3158 - val_loss: 1.6448 - val_accuracy: 0.3628\n",
      "Epoch 36/50\n",
      "110/110 [==============================] - 253s 2s/step - loss: 1.7140 - accuracy: 0.3309 - val_loss: 1.6516 - val_accuracy: 0.3602\n",
      "Epoch 37/50\n",
      "110/110 [==============================] - 204s 2s/step - loss: 1.7470 - accuracy: 0.3166 - val_loss: 1.6604 - val_accuracy: 0.3498\n",
      "Epoch 38/50\n",
      "110/110 [==============================] - 217s 2s/step - loss: 1.7339 - accuracy: 0.3126 - val_loss: 1.6436 - val_accuracy: 0.3663\n",
      "Epoch 39/50\n",
      "110/110 [==============================] - 210s 2s/step - loss: 1.7219 - accuracy: 0.3192 - val_loss: 1.6449 - val_accuracy: 0.3698\n",
      "Epoch 40/50\n",
      "110/110 [==============================] - 203s 2s/step - loss: 1.7232 - accuracy: 0.3264 - val_loss: 1.6487 - val_accuracy: 0.3637\n",
      "Epoch 41/50\n",
      "110/110 [==============================] - 209s 2s/step - loss: 1.7302 - accuracy: 0.3244 - val_loss: 1.6515 - val_accuracy: 0.3559\n",
      "Epoch 42/50\n",
      "110/110 [==============================] - 219s 2s/step - loss: 1.7322 - accuracy: 0.3258 - val_loss: 1.6415 - val_accuracy: 0.3594\n",
      "Epoch 43/50\n",
      "110/110 [==============================] - 221s 2s/step - loss: 1.7264 - accuracy: 0.3272 - val_loss: 1.6278 - val_accuracy: 0.3750\n",
      "Epoch 44/50\n",
      "110/110 [==============================] - 224s 2s/step - loss: 1.7216 - accuracy: 0.3252 - val_loss: 1.6460 - val_accuracy: 0.3689\n",
      "Epoch 45/50\n",
      "110/110 [==============================] - 224s 2s/step - loss: 1.7247 - accuracy: 0.3255 - val_loss: 1.6349 - val_accuracy: 0.3741\n",
      "Epoch 46/50\n",
      "110/110 [==============================] - 244s 2s/step - loss: 1.7098 - accuracy: 0.3355 - val_loss: 1.6178 - val_accuracy: 0.3724\n",
      "Epoch 47/50\n",
      "110/110 [==============================] - 218s 2s/step - loss: 1.7169 - accuracy: 0.3361 - val_loss: 1.6260 - val_accuracy: 0.3663\n",
      "Epoch 48/50\n",
      "110/110 [==============================] - 223s 2s/step - loss: 1.7095 - accuracy: 0.3201 - val_loss: 1.6310 - val_accuracy: 0.3828\n",
      "Epoch 49/50\n",
      "110/110 [==============================] - 219s 2s/step - loss: 1.7286 - accuracy: 0.3238 - val_loss: 1.6231 - val_accuracy: 0.3689\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 221s 2s/step - loss: 1.7071 - accuracy: 0.3321 - val_loss: 1.6101 - val_accuracy: 0.3793\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    baseball       0.31      0.52      0.39       183\n",
      "  basketball       0.33      0.26      0.29       122\n",
      "      boxing       0.45      0.65      0.53       176\n",
      "    football       0.23      0.14      0.18       196\n",
      "  gymnastics       0.39      0.15      0.21       178\n",
      "      hockey       0.35      0.20      0.25       142\n",
      "  ice_hockey       0.50      0.69      0.58       177\n",
      "\n",
      "    accuracy                           0.38      1174\n",
      "   macro avg       0.37      0.37      0.35      1174\n",
      "weighted avg       0.37      0.38      0.35      1174\n",
      "\n",
      "[INFO] serializing network...\n"
     ]
    }
   ],
   "source": [
    "!python3.8 train.py \\\n",
    "   --dataset Sports-Type-Classifier/data \\\n",
    "   --model model/activity.model \\\n",
    "   --label-bin model/lb.pickle \\\n",
    "   --epochs 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions: ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model and label binarizer...\n",
      "2021-11-06 14:38:13.980120: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-06 14:38:18.009287: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "[INFO] cleaning up...\n"
     ]
    }
   ],
   "source": [
    "!python3.8 predict_video.py \\\n",
    "    --model model/activity.model \\\n",
    "    --label-bin model/lb.pickle \\\n",
    "    --input clips/tennis.mp4 \\\n",
    "    --output output/tennis_1frame.avi \\\n",
    "    --size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions: VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model and label binarizer...\n",
      "2021-11-06 14:40:04.690964: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-06 14:40:08.053175: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "[INFO] cleaning up...\n"
     ]
    }
   ],
   "source": [
    "!python3.8 predict_video.py \\\n",
    "    --model model/activity.model \\\n",
    "    --label-bin model/lb.pickle \\\n",
    "    --input clips/tennis.mp4 \\\n",
    "    --output output/tennis_128frames_smoothened.avi \\\n",
    "    --size 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions: DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3.8 predict_video.py \\\n",
    "    --model model/activity.model \\\n",
    "    --label-bin model/lb.pickle \\\n",
    "    --input clips/lifting.mp4 \\\n",
    "    --output output/lifting_1frame.avi \\\n",
    "    --size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions: InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3.8 predict_video.py \\\n",
    "    --model model/activity.model \\\n",
    "    --label-bin model/lb.pickle \\\n",
    "    --input clips/lifting.mp4 \\\n",
    "    --output output/lifting_128frames_smoothened.avi \\\n",
    "    --size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3.8 predict_video.py \\\n",
    "    --model model/activity.model \\\n",
    "    --label-bin model/lb.pickle \\\n",
    "    --input clips/soccer.mp4 \\\n",
    "    --output output/soccer_128frames_smoothened.avi \\\n",
    "    --size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
